The starting point for estimations is the fact that a modern computer can perform
some hundreds of millions of operations i.e. 10^8 operations in a second.

For example, assume that the time limit for a problem is one second and the
input size is n = 10^5. If the time complexity is O(n^2), 
the algorithm will perform about (10^5)^2 = 10^10 operations. 
This should take at least some tens of seconds, so the algorithm seems to be too slow for solving the problem.

On the other hand, given the input size, we can try to guess the required time
complexity of the algorithm that solves the problem. The following table contains
some useful estimates assuming a time limit of one second.

input size       required time complexity
  n <= 10            O(n!)
  n <= 20            O(2^n)
  n <= 500           O(n^3)
  n <= 5000          O(n^2)
  n <= 10^6          O(nlogn) or O(n)
  n is large         O(1) or O(logn)



-> Complexity classes
 The following list contains common time complexities of algorithms:

    O(1) The running time of a constant-time algorithm does not depend on the
    input size. A typical constant-time algorithm is a direct formula that
    calculates the answer.

    O(logn) A logarithmic algorithm often halves the input size at each step. The
    running time of such an algorithm is logarithmic, because log2 n equals the
    number of times n must be divided by 2 to get 1.

    O(n^1/2) A square root algorithm is slower than O(logn) but faster than O(n).

    O(n) A linear algorithm goes through the input a constant number of times. This
    is often the best possible time complexity, because it is usually necessary to
    access each input element at least once before reporting the answer.

    O(nlogn) This time complexity often indicates that the algorithm sorts the input,
    because the time complexity of efficient sorting algorithms is O(nlogn).
    Another possibility is that the algorithm uses a data structure where each
    operation takes O(logn) time.

    O(n^2) A quadratic algorithm often contains two nested loops. It is possible to
    go through all pairs of the input elements in O(n^2) time.

    O(n^3) A cubic algorithm often contains three nested loops. It is possible to go
    through all triplets of the input elements in O(n^3) time.

    O(2^n) This time complexity often indicates that the algorithm iterates through
    all subsets of the input elements. For example, the subsets of {1,2,3} are empty_set,
    {1}, {2}, {3}, {1,2}, {1,3}, {2,3} and {1,2,3}.

    O(n!) This time complexity often indicates that the algorithm iterates through
    all permutations of the input elements. For example, the permutations of
    {1,2,3} are (1,2,3), (1,3,2), (2,1,3), (2,3,1), (3,1,2) and (3,2,1).



    Notes: 
    ** Constraint on N (<= 20) (i.e. size of array) hints towards bitmasking + DP.